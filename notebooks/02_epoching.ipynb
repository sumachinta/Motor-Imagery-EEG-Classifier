{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd89fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18999aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, importlib.util, os\n",
    "parentPath = Path.cwd().parent\n",
    "sys.path.insert(0, str(parentPath))  # add project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from src.preprocessing import raw_data_filter, get_events_and_ids_eegbci, make_epochs\n",
    "from src.datasets_eegbci import load_eegbci_raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = Path(f\"{parentPath}/data/raw\")\n",
    "derivedPath = Path(f\"{parentPath}/data/derivatives\")\n",
    "derivedPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# choose  subjects & MI runs:\n",
    "SUBJECTS = np.arange(1, 16)  # 1-109\n",
    "RUNS_MI  = [3,4,5,6,7,8,9,10,11,12,13,14]  # fists L/R; 4/8/12 are IMAGERY, 3/7/11 are EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws, files = load_eegbci_raws(SUBJECTS, RUNS_MI, cache_dir=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raws)):\n",
    "    events, anno_map = mne.events_from_annotations(raws[i])\n",
    "    print(f\"File {i+1}/{len(raws)}: Annotations: {list(anno_map.keys())}  Events: {np.unique(events[:,2])}\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = []\n",
    "summary_rows = []\n",
    "for raw, fname in zip(raws, files):\n",
    "    print(\"Processing:\", fname)\n",
    "    # Basic clean (safe harmonics per sfreq)\n",
    "    raw_c = raw_data_filter(raw, line_freq=60)  # use 50 if your subject is EU\n",
    "\n",
    "    # Optional montage\n",
    "    try:\n",
    "        raw_c.set_montage('standard_1020')\n",
    "    except Exception as e:\n",
    "        print(\"No montage applied:\", e)\n",
    "\n",
    "    # Events & event_id tailored to the run number\n",
    "    # events, event_id, inv_map, run = get_events_and_ids_eegbci(raw_c, two_class_only=True)\n",
    "    # print(\"Run:\", run, \"event_id:\", event_id)\n",
    "    events, event_id, inv_map, run = get_events_and_ids_eegbci(raw_c, two_class_only=True)\n",
    "    # print(\"Run:\", run, \"event_id:\", event_id)\n",
    "    # print(\"Unique event codes in events:\", np.unique(events[:,2]))\n",
    "\n",
    "    # Epochs\n",
    "    tmin, tmax = -0.2, 0.8\n",
    "    baseline = (None, 0)\n",
    "    epochs = make_epochs(raw_c, events, event_id, tmin=tmin, tmax=tmax,\n",
    "                         reject_ptp_uV=150.0, flat_uV=1.0)\n",
    "\n",
    "    # quick class counts\n",
    "    y = epochs.events[:, -1]\n",
    "    counts = {inv_map[int(k)]: int(v) for k, v in zip(*np.unique(y, return_counts=True))}\n",
    "    print(\"Counts:\", counts)\n",
    "\n",
    "    # Save epochs per file\n",
    "    out = derivedPath / f\"epochs_S{Path(fname).name.split('S')[-1].replace('.edf','')}-epo.fif\"\n",
    "    epochs.save(out, overwrite=True)\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "    all_epochs.append(epochs)\n",
    "    summary_rows.append((fname, run, counts))\n",
    "len(all_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8992fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one epochs object to visualize\n",
    "epoch_index = 122\n",
    "epoch = all_epochs[epoch_index]\n",
    "print(f\"Length of epoch: {len(epoch)}\")\n",
    "# epoch.drop_log\n",
    "epoch.plot_drop_log()\n",
    "if len(epoch)==0:\n",
    "    print(\"⚠️ No epochs to plot (all dropped). Showing drop log instead.\")\n",
    "    fig = epoch.plot_drop_log(show=False)  # always works, even if empty\n",
    "else:\n",
    "    psd = epoch.compute_psd(fmin=1, fmax=40, method=\"welch\")\n",
    "    fig = psd.plot(average=True, show=False)\n",
    "    # ERP by class name\n",
    "    labels = list(epoch.event_id.keys())\n",
    "    for lab in labels:\n",
    "        epoch[lab].average().plot(spatial_colors=True, titles=f\"ERP: {lab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573af278",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_FILES = sorted(derivedPath.glob(\"*-epo.fif\"))\n",
    "print(len(EPO_FILES), \"epoch files found\")\n",
    "\n",
    "rows = []\n",
    "for f in EPO_FILES:\n",
    "    ep = mne.read_epochs(f, preload=False, verbose=False)\n",
    "    y = ep.events[:, -1]\n",
    "    u, c = np.unique(y, return_counts=True)\n",
    "    # drop log summary\n",
    "    dropped = sum(len(x)>0 for x in ep.drop_log)\n",
    "    kept = len(ep)\n",
    "    drop_rate = dropped / (dropped + kept) if (dropped+kept)>0 else 0.\n",
    "    rows.append(dict(\n",
    "        file=str(f.name),\n",
    "        sfreq=float(ep.info[\"sfreq\"]),\n",
    "        n_ch=int(len(ep.ch_names)),\n",
    "        classes=\"/\".join(ep.event_id.keys()),\n",
    "        counts=\";\".join(f\"{int(ui)}:{int(ci)}\" for ui,ci in zip(u,c)),\n",
    "        kept=int(kept),\n",
    "        dropped=int(dropped),\n",
    "        drop_rate=float(drop_rate),\n",
    "    ))\n",
    "len(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd735d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Path(f\"{parentPath}/results/results.csv\")\n",
    "res.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with res.open(\"w\", newline=\"\") as f:        # <-- 'w' = overwrite\n",
    "    w = DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    w.writeheader()\n",
    "    w.writerows(rows)\n",
    "\n",
    "print(f\"Wrote {len(rows)} rows to {res} (overwrote any previous file).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGS = Path(f\"{parentPath}/figs\"); FIGS.mkdir(exist_ok=True, parents=True)\n",
    "for f in EPO_FILES:\n",
    "    ep = mne.read_epochs(f, preload=True, verbose=False)\n",
    "    if len(ep) == 0:\n",
    "        ep.plot_drop_log(show=False).savefig(FIGS / f\"droplog_{f.stem}.png\", dpi=150); continue\n",
    "\n",
    "    fig = ep.compute_psd(fmin=1, fmax=40).plot(average=True, show=False)\n",
    "    fig.savefig(FIGS / f\"psd_{f.stem}.png\", dpi=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c60891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurodecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
